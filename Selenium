
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
#IMPORTANT: Webdriver requires chrome driver, which is put into the system PATH

# Creating a webdriver instance
driver = webdriver.Chrome()
 
# Opening linkedIn's login page
driver.get("https://www.linkedin.com/login")
 
# waiting for the page to load
time.sleep(3)
 
# entering username
username = driver.find_element(By.ID, "username")
 
# In case of an error, try changing the element
# tag used here.
 
# Enter Your Email Address
username.send_keys("")  
 
# entering password
pword = driver.find_element(By.ID, "password")
# In case of an error, try changing the element 
# tag used here.
 
# Enter Your Password
pword.send_keys("")        
 
# Clicking on the log in button
# Format (syntax) of writing XPath --> 
# //tagname[@attribute='value']
driver.find_element(By.XPATH, "//button[@type='submit']").click()
# In case of an error, try changing the
# XPath used here.

#iterate through every job

soup = BeautifulSoup(driver.page_source, "html.parser")

job_listings = soup.find_all(
        "div",
        class_="flex-grow-1 artdeco-entity-lockup__content ember-view",
    )
print(len(job_listings))

for job in job_listings:
    element = driver.find_element(By.XPATH, f"//*[@id='{job.get('id')}']")
    element.click()

#individual job function
def load_job_data(keywords):
    soup = BeautifulSoup(driver.page_source, "html.parser")

    #needs to be adjusted based on screen size; this is calibrated for vertical monitor fullscreen
    scroll_origin = ScrollOrigin.from_viewport(500, 500)
    ActionChains(driver)\
        .scroll_from_origin(scroll_origin, 0, 5000)\
        .perform()
    
    #description = soup.find('div', {'class': 'jobs-description__content jobs-description-content'})
    description = driver.find_element(By.XPATH, '//*[@id="job-details"]')
    #print(description.text)

    
    for word in keywords:
        if word.lower() in description.text.lower():
            job_name = soup.find('span', {'class': 'job-details-jobs-unified-top-card__job-title-link'})
            #print(job_name.text.strip())
            job_link = soup.find('a', {'class': 'app-aware-link'})
            print(job_link)
            break
        else:
            print("not found")

#text.strip()
    
load_job_data(["NLP"])
    time.sleep(0.5)


